{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Constructions\n",
    "\n",
    "Explore using RoBERTa to determine correct vs incorrect on 2 sample constructions types (Caused-Motion and Way), 72 sentence pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Keep only sentence pairs where the rating difference is >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/paired_sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[abs(data.Rating1 - data.Rating2) >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Rating1</th>\n",
       "      <th>Rating2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>The audience laughed Bob off the stage.</td>\n",
       "      <td>The performers laughed Bob off the theatre.</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>The audience laughed Bob off the stage.</td>\n",
       "      <td>The singers laughed Bob off the movie.</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>John chopped carrots into the salad.</td>\n",
       "      <td>John chopped oranges into the bread.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "      <td>The professor invited us into his office.</td>\n",
       "      <td>The teacher invited us into his desk.</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CM</td>\n",
       "      <td>0</td>\n",
       "      <td>The key allowed John into the house.</td>\n",
       "      <td>The door allowed John into the condo.</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Acc                                  Sentence1  \\\n",
       "0   CM    1    The audience laughed Bob off the stage.   \n",
       "1   CM    1    The audience laughed Bob off the stage.   \n",
       "3   CM    1       John chopped carrots into the salad.   \n",
       "5   CM    1  The professor invited us into his office.   \n",
       "7   CM    0       The key allowed John into the house.   \n",
       "\n",
       "                                     Sentence2  Rating1  Rating2  \n",
       "0  The performers laughed Bob off the theatre.        5        3  \n",
       "1       The singers laughed Bob off the movie.        5        0  \n",
       "3         John chopped oranges into the bread.        5        1  \n",
       "5        The teacher invited us into his desk.        5        0  \n",
       "7        The door allowed John into the condo.        4        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run RoBERTa\n",
    "\n",
    "This function is copy-pasted from the layerwise anomaly project, but has some serious limitations:\n",
    "\n",
    "1. Assumes sentences have the same length\n",
    "2. Assumes only one masked token differs\n",
    "\n",
    "Therefore the majority of sentences are excluded right now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"fill-mask\", model='roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_one(sent1, sent2):\n",
    "  toks1 = nlp.tokenizer(sent1, add_special_tokens=False)['input_ids']\n",
    "  toks2 = nlp.tokenizer(sent2, add_special_tokens=False)['input_ids']\n",
    "  \n",
    "  if len(toks1) != len(toks2):\n",
    "    return None\n",
    "\n",
    "  masked_toks = []\n",
    "  dtok1 = None\n",
    "  dtok2 = None\n",
    "  num_masks = 0\n",
    "  for ix in range(len(toks1)):\n",
    "    if toks1[ix] != toks2[ix]:\n",
    "      masked_toks.append(nlp.tokenizer.mask_token_id)\n",
    "      num_masks += 1\n",
    "      dtok1 = toks1[ix]\n",
    "      dtok2 = toks2[ix]\n",
    "    else:\n",
    "      masked_toks.append(toks1[ix])\n",
    "  \n",
    "  if num_masks != 1:\n",
    "    return None\n",
    "  \n",
    "  res = nlp(nlp.tokenizer.decode(masked_toks), targets=[nlp.tokenizer.decode(dtok1), nlp.tokenizer.decode(dtok2)])\n",
    "  return res[0]['token'] == dtok1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frank dug his way out of prison.\n",
      "Frank dug his way out of cell.\n",
      "Sentence 1 is better\n",
      "\n",
      "Frank dug his way out of prison.\n",
      "Frank dug his way out of courthouse.\n",
      "Sentence 1 is better\n",
      "\n",
      "Bob worked his way to the top of his profession.\n",
      "Bob worked his way to the top of his degree.\n",
      "Sentence 1 is better\n",
      "\n",
      "Sam joked his way into the meeting.\n",
      "Sam joked his way into the date.\n",
      "Sentence 1 is better\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, row in data.iterrows():\n",
    "  result = fill_one(row['Sentence1'], row['Sentence2'])\n",
    "  if result is None:\n",
    "    continue\n",
    "  print(row['Sentence1'])\n",
    "  print(row['Sentence2'])\n",
    "  print(f'Sentence {1 if result else 2} is better')\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
