{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonse Sentence Generation\n",
    "\n",
    "Generate nonsense sentences similar to Johnson and Goldberg (2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "import scipy\n",
    "\n",
    "import src.sent_encoder\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain list of singular nouns, adjectives, past-tense verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "penn = nltk.corpus.reader.bracket_parse.BracketParseCorpusReader(\"../data/PTB3\", \".*\\.tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49207"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(penn.parsed_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "singular_nouns = defaultdict(int)\n",
    "adjectives = defaultdict(int)\n",
    "past_verbs = defaultdict(int)\n",
    "\n",
    "for tree in penn.parsed_sents():\n",
    "  for leaf in tree.subtrees(lambda t: t.height() == 2):\n",
    "    if leaf.label() == \"NN\":\n",
    "      singular_nouns[leaf[0].lower()] += 1\n",
    "    if leaf.label() == \"JJ\":\n",
    "      adjectives[leaf[0].lower()] += 1\n",
    "    if leaf.label() == \"VBD\":\n",
    "      past_verbs[leaf[0].lower()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out words that are too low-frequency\n",
    "singular_nouns = dict(filter(lambda w: w[1] >= 10, singular_nouns.items()))\n",
    "adjectives = dict(filter(lambda w: w[1] >= 10, adjectives.items()))\n",
    "past_verbs = dict(filter(lambda w: w[1] >= 10, past_verbs.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996\n",
      "843\n",
      "350\n"
     ]
    }
   ],
   "source": [
    "singular_nouns = list(sorted(singular_nouns))\n",
    "adjectives = list(sorted(adjectives))\n",
    "past_verbs = list(sorted(past_verbs))\n",
    "\n",
    "print(len(singular_nouns))\n",
    "print(len(adjectives))\n",
    "print(len(past_verbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get contextual vecs for gave/made/put/took"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/bnc.pkl\", \"rb\") as f:\n",
    "  bnc_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER = 11\n",
    "enc = src.sent_encoder.SentEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototype_vecs = {\n",
    "  'gave': enc.avg_contextual_word_vec(bnc_data, \"gave\")[LAYER],\n",
    "  'made': enc.avg_contextual_word_vec(bnc_data, \"made\")[LAYER],\n",
    "  'put': enc.avg_contextual_word_vec(bnc_data, \"put\")[LAYER],\n",
    "  'took': enc.avg_contextual_word_vec(bnc_data, \"took\")[LAYER],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate vecs for \"gave\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "perek_data = pd.read_csv(\"../data/perek-templated.csv\")\n",
    "\n",
    "gave_ditransitive_sents = [s for s in perek_data[perek_data.construction == 'ditransitive'].sentence if \"gave\" in s]\n",
    "gave_caused_motion_sents = [s for s in perek_data[perek_data.construction == 'to-dative'].sentence if \"gave\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototype_vecs = {\n",
    "  'gave-bnc': enc.avg_contextual_word_vec(bnc_data, \"gave\")[LAYER],\n",
    "  'gave-ditransitive': enc.avg_contextual_word_vec(gave_ditransitive_sents, \"gave\")[LAYER],\n",
    "  'gave-caused-motion': enc.avg_contextual_word_vec(gave_caused_motion_sents, \"gave\")[LAYER],\n",
    "  'gave-balanced': enc.avg_contextual_word_vec(gave_ditransitive_sents + gave_caused_motion_sents, \"gave\")[LAYER],\n",
    "  'gave-decontextual': enc.contextual_token_vecs([\"gave\"])[1][0][0][LAYER],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sentences of each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "NUM_SENTENCES_PER_CXN = 5000\n",
    "templated_sentences = defaultdict(list)\n",
    "\n",
    "# Ditransitive: S/he nonseV-ed him/her the nonseN\n",
    "for i in range(NUM_SENTENCES_PER_CXN):\n",
    "  pronoun1 = random.choice([\"He\", \"She\"])\n",
    "  pronoun2 = random.choice([\"him\", \"her\"])\n",
    "  nonse_verb = random.choice(past_verbs)\n",
    "  nonse_noun = random.choice(singular_nouns)\n",
    "  templated_sentences['ditransitive'].append((\n",
    "    f\"{pronoun1} {nonse_verb} {pronoun2} the {nonse_noun}.\",\n",
    "    nonse_verb\n",
    "  ))\n",
    "  \n",
    "# Resultative: S/he nonseV-ed it nonseAdj.\n",
    "for i in range(NUM_SENTENCES_PER_CXN):\n",
    "  pronoun1 = random.choice([\"He\", \"She\"])\n",
    "  nonse_verb = random.choice(past_verbs)\n",
    "  nonse_adj = random.choice(adjectives)\n",
    "  templated_sentences['resultative'].append((\n",
    "    f\"{pronoun1} {nonse_verb} it {nonse_adj}.\",\n",
    "    nonse_verb\n",
    "  ))\n",
    "  \n",
    "# Caused-motion: S/he nonseV-ed it on the nonseN.\n",
    "for i in range(NUM_SENTENCES_PER_CXN):\n",
    "  pronoun1 = random.choice([\"He\", \"She\"])\n",
    "  nonse_verb = random.choice(past_verbs)\n",
    "  nonse_noun = random.choice(singular_nouns)\n",
    "  templated_sentences['caused-motion'].append((\n",
    "    f\"{pronoun1} {nonse_verb} it on the {nonse_noun}.\",\n",
    "    nonse_verb\n",
    "  ))\n",
    "  \n",
    "# Removal: S/he nonseV-ed it from him/her.\n",
    "for i in range(NUM_SENTENCES_PER_CXN):\n",
    "  pronoun1 = random.choice([\"He\", \"She\"])\n",
    "  pronoun2 = random.choice([\"him\", \"her\"])\n",
    "  nonse_verb = random.choice(past_verbs)\n",
    "  templated_sentences['removal'].append((\n",
    "    f\"{pronoun1} {nonse_verb} it from {pronoun2}.\",\n",
    "    nonse_verb\n",
    "  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get distances from cxn-verbs to proto-verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_dist_results = []\n",
    "\n",
    "for cxn_type, cxn_sentences_and_verbs in templated_sentences.items():\n",
    "  cxn_sentences = [t[0] for t in cxn_sentences_and_verbs]\n",
    "  cxn_verbs = [t[1] for t in cxn_sentences_and_verbs]\n",
    "  cxn_verb_vecs = enc.sentence_vecs(cxn_sentences, cxn_verbs)[:, LAYER]\n",
    "  \n",
    "  for proto_verb, proto_verb_vec in prototype_vecs.items():\n",
    "    for i, cxn_verb_vec in enumerate(cxn_verb_vecs):\n",
    "      dist = np.linalg.norm(proto_verb_vec - cxn_verb_vec)\n",
    "      #dist = scipy.spatial.distance.cosine(proto_verb_vec, cxn_verb_vec)\n",
    "      verb_dist_results.append(pd.Series({\n",
    "        'cxn_sentence': cxn_sentences[i],\n",
    "        'cxn': cxn_type,\n",
    "        'verb': proto_verb,\n",
    "        'dist': dist,\n",
    "      }))\n",
    "      \n",
    "verb_dist_results = pd.DataFrame(verb_dist_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ditransitive gave-bnc 11.89890238647461 1.1858078835315617\n",
      "resultative gave-bnc 11.92425343208313 1.2382925883849938\n",
      "caused-motion gave-bnc 11.691192469120026 1.216427248591975\n",
      "removal gave-bnc 11.74043079328537 1.4384559320850094\n",
      "ditransitive gave-ditransitive 12.956236758136749 1.0979010798756514\n",
      "resultative gave-ditransitive 13.635849875450134 1.163551363660923\n",
      "caused-motion gave-ditransitive 13.457953846549987 1.1173115514357612\n",
      "removal gave-ditransitive 13.4145749666214 1.283106238319434\n",
      "ditransitive gave-caused-motion 13.098836085033417 1.147763675920884\n",
      "resultative gave-caused-motion 13.447416508674621 1.2799567645610712\n",
      "caused-motion gave-caused-motion 13.092678824234008 1.16962856020809\n",
      "removal gave-caused-motion 12.981258228492736 1.3712386897713265\n",
      "ditransitive gave-balanced 12.822159089183808 1.1270710939695043\n",
      "resultative gave-balanced 13.366851495361328 1.225373151157081\n",
      "caused-motion gave-balanced 13.109967133903503 1.152106266864675\n",
      "removal gave-balanced 13.036358206176757 1.335721950835173\n",
      "ditransitive gave-decontextual 18.636688849639892 0.6347413206954058\n",
      "resultative gave-decontextual 18.275927492523195 0.7276901599858344\n",
      "caused-motion gave-decontextual 18.268875506591797 0.5547084076984097\n",
      "removal gave-decontextual 18.597058947753908 0.6059173433158257\n"
     ]
    }
   ],
   "source": [
    "for verb in prototype_vecs.keys():\n",
    "  for cxn in templated_sentences.keys():\n",
    "    m = verb_dist_results[(verb_dist_results.cxn == cxn) & (verb_dist_results.verb == verb)].mean()\n",
    "    sd = verb_dist_results[(verb_dist_results.cxn == cxn) & (verb_dist_results.verb == verb)].std()\n",
    "    print(cxn, verb, float(m), float(sd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
