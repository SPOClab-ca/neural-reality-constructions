{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonse Sentence Generation\n",
    "\n",
    "Generate nonsense sentences similar to Johnson and Goldberg (2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "import src.sent_encoder\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain list of singular nouns, adjectives, past-tense verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "penn = nltk.corpus.reader.bracket_parse.BracketParseCorpusReader(\"../data/PTB3\", \".*\\.tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49207"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(penn.parsed_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "singular_nouns = set()\n",
    "adjectives = set()\n",
    "past_verbs = set()\n",
    "\n",
    "for tree in penn.parsed_sents():\n",
    "  for leaf in tree.subtrees(lambda t: t.height() == 2):\n",
    "    if leaf.label() == \"NN\":\n",
    "      singular_nouns.add(leaf[0].lower())\n",
    "    if leaf.label() == \"JJ\":\n",
    "      adjectives.add(leaf[0].lower())\n",
    "    if leaf.label() == \"VBD\":\n",
    "      past_verbs.add(leaf[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8444\n",
      "5163\n",
      "1678\n"
     ]
    }
   ],
   "source": [
    "singular_nouns = list(singular_nouns)\n",
    "adjectives = list(adjectives)\n",
    "past_verbs = list(past_verbs)\n",
    "\n",
    "print(len(singular_nouns))\n",
    "print(len(adjectives))\n",
    "print(len(past_verbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get contextual vecs for gave/made/put/took"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/bnc.pkl\", \"rb\") as f:\n",
    "  bnc_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER = 11\n",
    "enc = src.sent_encoder.SentEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "prototype_vecs = {\n",
    "  'gave': enc.avg_contextual_word_vec(bnc_data, \"gave\")[LAYER],\n",
    "  'made': enc.avg_contextual_word_vec(bnc_data, \"made\")[LAYER],\n",
    "  'put': enc.avg_contextual_word_vec(bnc_data, \"put\")[LAYER],\n",
    "  'took': enc.avg_contextual_word_vec(bnc_data, \"took\")[LAYER],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sentences of each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "NUM_SENTENCES_PER_CXN = 1000\n",
    "sentences = defaultdict(list)\n",
    "\n",
    "# Ditransitive: S/he nonseV-ed him/her the nonseN\n",
    "for i in range(NUM_SENTENCES_PER_CXN):\n",
    "  pronoun1 = random.choice([\"He\", \"She\"])\n",
    "  pronoun2 = random.choice([\"him\", \"her\"])\n",
    "  nonse_verb = random.choice(past_verbs)\n",
    "  nonse_noun = random.choice(singular_nouns)\n",
    "  sentences['ditransitive'].append(f\"{pronoun1} {nonse_verb} {pronoun2} the {nonse_noun}.\")\n",
    "  \n",
    "# Resultative: S/he nonseV-ed it nonseAdj.\n",
    "for i in range(NUM_SENTENCES_PER_CXN):\n",
    "  pronoun1 = random.choice([\"He\", \"She\"])\n",
    "  nonse_verb = random.choice(past_verbs)\n",
    "  nonse_adj = random.choice(adjectives)\n",
    "  sentences['resultative'].append(f\"{pronoun1} {nonse_verb} it {nonse_adj}.\")\n",
    "  \n",
    "# Caused-motion: S/he nonseV-ed it on the nonseN.\n",
    "for i in range(NUM_SENTENCES_PER_CXN):\n",
    "  pronoun1 = random.choice([\"He\", \"She\"])\n",
    "  nonse_verb = random.choice(past_verbs)\n",
    "  nonse_noun = random.choice(singular_nouns)\n",
    "  sentences['caused-motion'].append(f\"{pronoun1} {nonse_verb} it on the {nonse_noun}.\")\n",
    "  \n",
    "# Removal: S/he nonseV-ed it from him/her.\n",
    "for i in range(NUM_SENTENCES_PER_CXN):\n",
    "  pronoun1 = random.choice([\"He\", \"She\"])\n",
    "  pronoun2 = random.choice([\"him\", \"her\"])\n",
    "  nonse_verb = random.choice(past_verbs)\n",
    "  sentences['removal'].append(f\"{pronoun1} {nonse_verb} it from {pronoun2}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
