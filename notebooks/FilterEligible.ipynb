{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Eligible Sentences from FrameNet\n",
    "\n",
    "Find sentences that are possibly useful for perturbation.\n",
    "\n",
    "* Length of sentence must be <= 10 tokens. (16k sentences remaining)\n",
    "* One of the frame elements must be <= 3 tokens and contain a noun. (10k sentences remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_len(sent):\n",
    "  return len(sent.split())\n",
    "\n",
    "fn_sents = fn.exemplars()\n",
    "short_sentences = [sent for sent in fn_sents if approx_len(sent.text) <= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16425"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter sentences with a noun in one of its frame elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def is_overlapping(start1, end1, start2, end2):\n",
    "  return (start1 <= start2 and end1 > start2) or (start2 <= start1 and end2 > start1)\n",
    "\n",
    "print(is_overlapping(1, 2, 3, 4)) #False\n",
    "print(is_overlapping(1, 2, 2, 4)) #False\n",
    "print(is_overlapping(1, 2, 1, 4)) #True\n",
    "print(is_overlapping(1, 4, 1, 2)) #True\n",
    "print(is_overlapping(1, 4, 2, 3)) #True\n",
    "print(is_overlapping(1, 4, 4, 5)) #False\n",
    "print(is_overlapping(1, 4, 3, 5)) #True\n",
    "print(is_overlapping(1, 4, 0, 1)) #False\n",
    "print(is_overlapping(1, 4, 0, 5)) #True\n",
    "print(is_overlapping(1, 4, 0, 3)) #True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def pos_is_noun(pos_tag):\n",
    "  return 'nn' in pos_tag.lower()\n",
    "\n",
    "print(pos_is_noun('NN1')) #True\n",
    "print(pos_is_noun('PROPN')) #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_noun_target(sent):\n",
    "  for fe_start, fe_end, fe_name in sent.FE[0]:\n",
    "    fe_text = sent.text[fe_start:fe_end]\n",
    "    if approx_len(fe_text) <= 3:\n",
    "      for pos_start, pos_end, pos_tag in sent.POS:\n",
    "        if pos_is_noun(pos_tag) and is_overlapping(fe_start, fe_end, pos_start, pos_end):\n",
    "          return True\n",
    "  return False\n",
    "\n",
    "noun_target_sents = [sent for sent in short_sentences if has_noun_target(sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10438"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun_target_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export random selection to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "export_sents = random.sample(noun_target_sents, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for sent in export_sents:\n",
    "  annotations = []\n",
    "  for span_start, span_end, fe_name in sent.FE[0]:\n",
    "    annotations.append(f\"{fe_name}: '{sent.text[span_start:span_end]}'\")\n",
    "    \n",
    "  df.append(pd.Series({\n",
    "    'fn_id': sent.ID,\n",
    "    'frame': sent.frame.name,\n",
    "    'text': sent.text,\n",
    "    'annotations': '\\n'.join(annotations),\n",
    "  }))\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"short_fn_exemplars.csv\", index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
