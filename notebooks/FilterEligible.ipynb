{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Eligible Sentences from FrameNet\n",
    "\n",
    "Find sentences that are possibly useful for perturbation.\n",
    "\n",
    "* Length of sentence must be <= 10 tokens. (16k sentences remaining)\n",
    "* One of the frame elements must be <= 3 tokens and contain exactly one noun. (9.6k sentences remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_len(sent):\n",
    "  return len(sent.split())\n",
    "\n",
    "fn_sents = fn.exemplars()\n",
    "short_sentences = [sent for sent in fn_sents if approx_len(sent.text) <= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16425"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter sentences with a noun in one of its frame elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlapping(start1, end1, start2, end2):\n",
    "  return (start1 <= start2 and end1 > start2) or (start2 <= start1 and end2 > start1)\n",
    "\n",
    "assert not is_overlapping(1, 2, 3, 4)\n",
    "assert not is_overlapping(1, 2, 2, 4)\n",
    "assert is_overlapping(1, 2, 1, 4)\n",
    "assert is_overlapping(1, 4, 1, 2)\n",
    "assert is_overlapping(1, 4, 2, 3)\n",
    "assert not is_overlapping(1, 4, 4, 5)\n",
    "assert is_overlapping(1, 4, 3, 5)\n",
    "assert not is_overlapping(1, 4, 0, 1)\n",
    "assert is_overlapping(1, 4, 0, 5)\n",
    "assert is_overlapping(1, 4, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters for common (non-proper) nouns in PENN and BNC tagsets\n",
    "def pos_is_noun(pos_tag):\n",
    "  return 'nn' in pos_tag.lower() and 'np' not in pos_tag.lower()\n",
    "\n",
    "assert not pos_is_noun('VB')\n",
    "assert pos_is_noun('NN1')\n",
    "assert not pos_is_noun('NNPS')\n",
    "assert not pos_is_noun('NN1-NP0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_targets(sent):\n",
    "  noun_targets = []\n",
    "  for fe_start, fe_end, fe_name in sent.FE[0]:\n",
    "    fe_text = sent.text[fe_start:fe_end]\n",
    "    nouns_in_fe = []\n",
    "    for pos_start, pos_end, pos_tag in sent.POS:\n",
    "      if pos_is_noun(pos_tag) and is_overlapping(fe_start, fe_end, pos_start, pos_end):\n",
    "        nouns_in_fe.append(sent.text[pos_start:pos_end])\n",
    "    \n",
    "    if approx_len(fe_text) <= 3 and len(nouns_in_fe) == 1:\n",
    "      noun_targets.append(nouns_in_fe[0])\n",
    "  return noun_targets\n",
    "\n",
    "noun_target_sents = []\n",
    "for sent in short_sentences:\n",
    "  noun_targets = get_noun_targets(sent)\n",
    "  if noun_targets != []:\n",
    "    noun_target_sents.append((sent, noun_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9657"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun_target_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export random selection to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "export_sents = random.sample(noun_target_sents, 100)\n",
    "#export_sents = noun_target_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for sent, noun_targets in export_sents:\n",
    "  annotations = []\n",
    "  annotations.append(('Target', sent.text[sent.Target[0][0]:sent.Target[0][1]]))\n",
    "  for span_start, span_end, fe_name in sent.FE[0]:\n",
    "    annotations.append((fe_name, sent.text[span_start:span_end]))\n",
    "    \n",
    "  df.append(pd.Series({\n",
    "    'frame': sent.frame.name,\n",
    "    'text': sent.text,\n",
    "    'noun_targets': json.dumps(noun_targets),\n",
    "    'annotations': json.dumps(annotations),\n",
    "  }))\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"short_fn_exemplars.csv\", index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
